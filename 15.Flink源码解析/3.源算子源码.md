# Flink 算子源码

## 构建执行环境

1. Flink api 通过StreamExecutionEnvironment.getExecutionEnvironment(); 方法获取对应的执行环境。
2. StreamExecutionEnvironment 类包含了创建DataStream方法。后续所有的转换操作都会以最初创建的 DataStream 为源头，进行算子的转换。
3. 等编写完Flink应用程序。必须调用 env.execute("Window WordCount"); 方法。执行整个应用程序。构建对应的 StreamGraph。提交到集群中运行。

## Flink算子整体概念

Flink 算子整体上分为三个部分：分别是

1. 源算子
   - 源算子常见的有
     1. 集合读取数据
     2. 顺序数字序列
     3. 文件/文件夹读取器
     4. DataGen 连接器
     5. Socket 连接器
     6. Kafka连接器
2. 转换算子
   - 基本转换函数
     1. map
     2. flatmap
     3. filter
   - 聚合算子
     1. KeyBy
     2. sum/min/max/minBy/maxBy
     3. reduce
   - 用户自定义函数
     1. Function Class
     2. Rich Function Classes
   - 物理分区算子
     1. global()
     2. forward()
     3. shuffle()
     4. rebalance()
     5. rescale()
     6. broadcast()
     7. keyBy()
   - 分流
     1. 测输出流
   - 基本合流操作
     1. Union
     2. Connect
3. 输出算子
   - 输出到文件
   - 输出到Kafka
   - 输出到Mysql
   - 自定义输出

## Socket源算子解析

以 Socket 源算子为例。其余源算子有时间在看源码解析：

1. 首先调用 `env.socketTextStream("localhost", 9999)` 方法构建Socket流。

2. 根据 socketTextStream 方法进入。有一个 方法是 ` public DataStreamSource<String> socketTextStream(String hostname, int port, String delimiter, long maxRetry)` 。这个方法内部调用了 两个方法。分别是 `new SocketTextStreamFunction(hostname, port, delimiter, maxRetry), "Socket Stream");`和 `public <OUT> DataStreamSource<OUT> addSource(SourceFunction<OUT> function, String sourceName) `

   ~~~java
    public DataStreamSource<String> socketTextStream(
               String hostname, int port, String delimiter, long maxRetry) {
           return addSource(
                   new SocketTextStreamFunction(hostname, port, delimiter, maxRetry), "Socket Stream");
    }
   
   ~~~

3. 首先看 `new SocketTextStreamFunction(hostname, port, delimiter, maxRetry), "Socket Stream");` 方法

   1. `SocketTextStreamFunction` 继承了 `SourceFunction` 接口。

      1. `SoucreFunction` 接口包含了3个实例。分别是 `SourceContext` 接口，`run` 方法 和 `cancel` 方法。而 `SourceFunction` 接口又继承自 `Function`接口。

         - 以下分别是 SourceFunction 源码和 Function源码

         ~~~java
         @Public
         public interface SourceFunction<T> extends Function, Serializable {
             void run(SourceContext<T> ctx) throws Exception;
             void cancel();
         
             // ------------------------------------------------------------------------
             //  source context
             // ------------------------------------------------------------------------
         
             interface SourceContext<T> {
                 void collect(T element);
                 
                 @PublicEvolving
                 void collectWithTimestamp(T element, long timestamp);
         
                 @PublicEvolving
                 void emitWatermark(Watermark mark);
         
                 @PublicEvolving
                 void markAsTemporarilyIdle();
         
                 Object getCheckpointLock();
         
                 void close();
             }
         }
         ~~~

         ~~~java
         public interface Function extends java.io.Serializable {}
         ~~~

      2. 通过上述源码可以知道，`Function` 接口是Flink所有算子的  `base interface`。而 `SourceFunction` 则继承了该类。并定义了 `run` 方法，用来生产数据。和对应的 `SourceContext` 接口，用来收集数据、生产水位线和 `checkpoint` 等操作。`SourceContext` 接口 先不做过多的源码解析，等后续研究收集数据、生产水位线和 `checkpoint`，在分析研究。

      3. 返回看 `SocketTextStreamFunction`。分别有 这几个对象：

         ![SocketTextStreamFunction 对象](.\SocketTextStreamFunction 对象.png)

         1. 重点看 `run` 方法。

            ~~~java
            @Override
                public void run(SourceContext<String> ctx) throws Exception {
                    final StringBuilder buffer = new StringBuilder();
                    long attempt = 0;
            
                    while (isRunning) {
            
                        try (Socket socket = new Socket()) {
                            currentSocket = socket;
            
                            LOG.info("Connecting to server socket " + hostname + ':' + port);
                            socket.connect(new InetSocketAddress(hostname, port), CONNECTION_TIMEOUT_TIME);
                            try (BufferedReader reader =
                                    new BufferedReader(new InputStreamReader(socket.getInputStream()))) {
            
                                char[] cbuf = new char[8192];
                                int bytesRead;
                                while (isRunning && (bytesRead = reader.read(cbuf)) != -1) {
                                    buffer.append(cbuf, 0, bytesRead);
                                    int delimPos;
                                    while (buffer.length() >= delimiter.length()
                                            && (delimPos = buffer.indexOf(delimiter)) != -1) {
                                        String record = buffer.substring(0, delimPos);
                                        // truncate trailing carriage return
                                        if (delimiter.equals("\n") && record.endsWith("\r")) {
                                            record = record.substring(0, record.length() - 1);
                                        }
                                        //这个方法收集 读取的 record
                                        // ctx 是flink运行的上下文。等后续run-time 运行环境可以再进一步进行解析。
                                        ctx.collect(record);
                                        buffer.delete(0, delimPos + delimiter.length());
                                    }
                                }
                            }
                        }
            
                        // if we dropped out of this loop due to an EOF, sleep and retry
                        // 这边是重试，socket如果断开了连接，同时flink没有收到 cancel 命令，则会等待重新连接。重连次数和间隔次数 依赖于
                        // maxNumRetries 和 delayBetweenRetries
                        if (isRunning) {
                            attempt++;
                            if (maxNumRetries == -1 || attempt < maxNumRetries) {
                                LOG.warn(
                                        "Lost connection to server socket. Retrying in "
                                                + delayBetweenRetries
                                                + " msecs...");
                                Thread.sleep(delayBetweenRetries);
                            } else {
                                // this should probably be here, but some examples expect simple exists of the
                                // stream source
                                // throw new EOFException("Reached end of stream and reconnects are not
                                // enabled.");
                                break;
                            }
                        }
                    }
            
                    // collect trailing data
                    if (buffer.length() > 0) {
                        ctx.collect(buffer.toString());
                    }
                }
            ~~~

      4. `Socket`算子真正干活的算子是 `SocketTextStreamFunction`。里面定义了`run`方法。`run`方法接收 `SourceContext`参数。用于接收 `run`方法产生的数据。

      5. 接下来解析 `public <OUT> DataStreamSource<OUT> addSource(SourceFunction<OUT> function, String sourceName)` 方法

         ~~~java
           //该方法接收一个 SourceFunction和算子名称，内部调用了 addSource 方法
           public <OUT> DataStreamSource<OUT> addSource(SourceFunction<OUT> function, String sourceName) {
                 return addSource(function, sourceName, null);
           }
           
           // 一路点下去，点到最基础的 addSource 方法
           //该方法接收四个参数，分别是
           //SourceFunction：里面定义了源算子操作
           // sourceName：源算子名称
           // typeInfo：算子计算类型
           // SourceFunction:算子类型-有界无界
            private <OUT> DataStreamSource<OUT> addSource(
                     final SourceFunction<OUT> function,
                     final String sourceName,
                     @Nullable final TypeInformation<OUT> typeInfo,
                     final Boundedness boundedness) {
                 checkNotNull(function);
                 checkNotNull(sourceName);
                 checkNotNull(boundedness);
         
                //解析算子计算类型
                 TypeInformation<OUT> resolvedTypeInfo =
                         getTypeInfo(function, sourceName, SourceFunction.class, typeInfo);
         
                 boolean isParallel = function instanceof ParallelSourceFunction;
         		
         		//清理闭包操作，可以不用理会。主要用于将可能不会序列化的类或者没有必要传输的类置为null
                 clean(function);
         		
         		//将 SourceFunction 进行包装，生成一个 StreamSource 类
                 final StreamSource<OUT, ?> sourceOperator = new StreamSource<>(function);
                
                //返回一个 DataStreamSource。里面接收了6个参数。最关键的是 this 和 sourceOperator
                 return new DataStreamSource<>(
                         this, resolvedTypeInfo, sourceOperator, isParallel, sourceName, boundedness);
             }
         ~~~

      6. 首先看 `final StreamSource<OUT, ?> sourceOperator = new StreamSource<>(function);` 方法。返回了 `StreamSource` 类。`StreamSource` 类又继承了 `AbstractUdfStreamOperator<OUT, F extends Function>` 抽象类。`AbstractUdfStreamOperator<OUT, F extends Function>` 继承了 `AbstractStreamOperator`抽象类和`OutputTypeConfigurable` 接口。而 `AbstractStreamOperator` 抽象类 往上还有 `StreamOperator`。可以先看一下，`StreamOperate` 抽象类的各类继承关系

         ![SocketTextStreamFunction 对象](.\StreamOperate继承关系.png)

         里面定义了各种算子操作。看一下 `StreamSource` 在哪个位置

         ![image-20250602162434185](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20250602162434185.png)

         可以看到 同级别还有非常多的其余算子。这可能说明了 `Flink` 的源码架构中，`StreamOperator` 封装了 `Function` 类。`Function`类定义了算子实际的操作。那 `StreamOperator` 在这个基础上，扩展了哪些功能。查看具体实现和 `run` 方法可以大概进行了解。

         ~~~java
         public StreamSource(SRC sourceFunction, boolean emitProgressiveWatermarks) {
                 super(sourceFunction);
         		
             	//算子连接的策略类型。这是个 enum 类。当前操作表明是头 head 头节点
                 this.chainingStrategy = ChainingStrategy.HEAD;
             	
                 this.emitProgressiveWatermarks = emitProgressiveWatermarks;
             }
         
         public void run(
                     final Object lockingObject,
                     final Output<StreamRecord<OUT>> collector,
                     final OperatorChain<?, ?> operatorChain)
                     throws Exception {
         
                 final TimeCharacteristic timeCharacteristic = getOperatorConfig().getTimeCharacteristic();
         
                 final Configuration configuration =
                         this.getContainingTask().getEnvironment().getTaskManagerInfo().getConfiguration();
                 final long latencyTrackingInterval =
                         getExecutionConfig().isLatencyTrackingConfigured()
                                 ? getExecutionConfig().getLatencyTrackingInterval()
                                 : configuration.getLong(MetricOptions.LATENCY_INTERVAL);
         
                 LatencyMarkerEmitter<OUT> latencyEmitter = null;
                 if (latencyTrackingInterval > 0) {
                     latencyEmitter =
                             new LatencyMarkerEmitter<>(
                                     getProcessingTimeService(),
                                     collector::emitLatencyMarker,
                                     latencyTrackingInterval,
                                     this.getOperatorID(),
                                     getRuntimeContext().getIndexOfThisSubtask());
                 }
         
                 final long watermarkInterval =
                         getRuntimeContext().getExecutionConfig().getAutoWatermarkInterval();
         
                //生成flink上下文实例，该实例定义了 水位线的生产方式等方法，并传递给 userFunction方法。
                 this.ctx =
                         StreamSourceContexts.getSourceContext(
                                 timeCharacteristic,
                                 getProcessingTimeService(),
                                 lockingObject,
                                 collector,
                                 watermarkInterval,
                                 -1,
                                 emitProgressiveWatermarks);
         
                 try {
                     //用户自定义的方法，对应的则是 Flink 的 source 函数
                     userFunction.run(ctx);
                 } finally {
                     if (latencyEmitter != null) {
                         latencyEmitter.close();
                     }
                 }
             }
         ~~~

      7. 接下来看 `DataStreamSource`。该方法返回了一个 真正的 `operate` 流。用作后续的转换操作。

         ~~~java
         //该方法接收一个 environment和 LegacySourceTransformation。
         public DataStreamSource(
                     StreamExecutionEnvironment environment,
                     TypeInformation<T> outTypeInfo,
                     StreamSource<T, ?> operator,
                     boolean isParallel,
                     String sourceName,
                     Boundedness boundedness) {
                 super(
                         environment,
                         new LegacySourceTransformation<>(
                                 sourceName,
                                 operator,
                                 outTypeInfo,
                                 environment.getParallelism(),
                                 boundedness));
         
                 this.isParallel = isParallel;
                 if (!isParallel) {
                     setParallelism(1);
                 }
             }
         
         //生成物理流，物理流接收一个StreamSource<T, ?> operator。并调用 SimpleOperatorFactory.of(operator) 进行包裹。返回 
         //return new SimpleUdfStreamOperatorFactory<OUT>((AbstractUdfStreamOperator) operator);
         public LegacySourceTransformation(
                     String name,
                     StreamSource<T, ?> operator,
                     TypeInformation<T> outputType,
                     int parallelism,
                     Boundedness boundedness) {
                 this(name, SimpleOperatorFactory.of(operator), outputType, parallelism, boundedness);
             }
             
         // 最后其实生成的是这个
         public class DataStream<T> {
         	protected final StreamExecutionEnvironment environment;
         
             protected final Transformation<T> transformation;
         
            //这个 DataStream 包含了 environment 和 对应的 transformation也就是上文的 LegacySourceTransformation。并返回
             public DataStream(StreamExecutionEnvironment environment, Transformation<T> transformation) {
                 this.environment =
                         Preconditions.checkNotNull(environment, "Execution Environment must not be null.");
                 this.transformation =
                         Preconditions.checkNotNull(
                                 transformation, "Stream Transformation must not be null.");
             }
         }
         ~~~

          

      8. 可以看到 一个源流经过一系列转换。会获得一个 `DataStream`。而这个转换主要围绕的是 `SourceFunction`、`Operator` 和 `Transformation` 三个方面。

         - `SourceFunction`继承自 `SourceFunction`：里面定义了 `run` 方法
         - `Operator`包裹 `SourceFunction`：增强了`run`方法。包括触发检查点、水位线等功能。
         - `Transformation`：则是包裹了 `Operator`，包括该转换算子名称，节点序列号等。

      9. 值得注意的是：老版本的`flink`用的 `SourceFunction`接口。但在新架构中，`flink` 希望用`Source`接口取代`SourceFunction` 接口。通过 `createEnumerator` 和 `createReader`两个方法。产生对应的分区切片和读取。从而简化数据分片，锁竞争和算子并行度的开发。后续会增加对`Kafkka`源算子的解读。在`DataStreamSource`类的构建方法中，新增了 构建方法。

         ~~~java
         //最后可以看到，所有的方法都会转换成 Transformation。
         //所以，在Flink中，Transformation是一等公民
         public DataStreamSource(
                     StreamExecutionEnvironment environment,
                     Source<T, ?, ?> source,
                     WatermarkStrategy<T> watermarkStrategy,
                     TypeInformation<T> outTypeInfo,
                     String sourceName) {
                 super(
                         environment,
                         new SourceTransformation<>(
                                 sourceName,
                                 source,
                                 watermarkStrategy,
                                 outTypeInfo,
                                 environment.getParallelism()));
                 this.isParallel = true;
         }
         ~~~

      
